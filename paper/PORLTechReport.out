\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Background}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Overview}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Optimistic RL}{section.2}% 4
\BOOKMARK [1][-]{section.3}{Optimistic Partially Observable RL Algorithm}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Learning}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Planning}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.3}{Point-Based Optimistic Planning Algorithm}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.4}{Optimistic Belief Point Backup}{section.3}% 9
\BOOKMARK [2][-]{subsection.3.5}{Optimistic Belief Update}{section.3}% 10
\BOOKMARK [1][-]{section.4}{Analysis}{}% 11
\BOOKMARK [2][-]{subsection.4.1}{Method of Moments Learning Algorithm}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.2}{Method of Moments Caveats}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.3}{Probably Approximate Correct Setting}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.4}{Sample Complexity Result}{section.4}% 15
\BOOKMARK [3][-]{subsubsection.4.4.1}{Difference in Belief States}{subsection.4.4}% 16
\BOOKMARK [3][-]{subsubsection.4.4.2}{Approximate Belief Tracking}{subsection.4.4}% 17
\BOOKMARK [3][-]{subsubsection.4.4.3}{What happens when the minimum entry in the observation matrix is 0}{subsection.4.4}% 18
\BOOKMARK [3][-]{subsubsection.4.4.4}{Generalized Induced Inequality}{subsection.4.4}% 19
\BOOKMARK [3][-]{subsubsection.4.4.5}{Main Theorem with actions}{subsection.4.4}% 20
\BOOKMARK [3][-]{subsubsection.4.4.6}{Assumptions}{subsection.4.4}% 21
\BOOKMARK [3][-]{subsubsection.4.4.7}{Proof}{subsection.4.4}% 22
\BOOKMARK [2][-]{subsection.4.5}{Applying the Theorem}{section.4}% 23
\BOOKMARK [3][-]{subsubsection.4.5.1}{POMDP as MDP over histories in an Episodic Task}{subsection.4.5}% 24
\BOOKMARK [1][-]{section.5}{Experiments}{}% 25
\BOOKMARK [1][-]{section.6}{Appendix}{}% 26
\BOOKMARK [2][-]{subsection.6.1}{Method of Moments Confidence Intervals}{section.6}% 27
\BOOKMARK [3][-]{subsubsection.6.1.1}{Resolving L2 Norm Confidence Intervals}{subsection.6.1}% 28
\BOOKMARK [3][-]{subsubsection.6.1.2}{Valid Probability Distributions}{subsection.6.1}% 29
\BOOKMARK [3][-]{subsubsection.6.1.3}{Disentangling Observations and Rewards}{subsection.6.1}% 30
\BOOKMARK [3][-]{subsubsection.6.1.4}{Deriving Transition Confidence Intervals}{subsection.6.1}% 31
